{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from utility import print_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "In this session you will be using deep learning to improve the results for image digit recognition problem. You will:\n",
    "- Build a Convolutional Neural Network (CNN).\n",
    "- Train and test your CNN.\n",
    "- Modify the CNN architecture to obtain better results.\n",
    "\n",
    "\n",
    "# Load the data.\n",
    "To load MNIST data from TensorFlow you will need to load the data in a MNIST dataset and give a sample of the content. To do this, follow these steps:\n",
    "\n",
    "__1. Paste and execute in a code cell the following command to ensure the dataset is accessible locally:.__\n",
    "```python\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('../Data/MNIST_data', one_hot=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting ../Data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting ../Data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ../Data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ../Data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('../Data/MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your code\n",
    "__2. Run the next code cell to ensure the recently created MNIST dataset is available and to see an example of an image.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUkAAAFuCAYAAAAMI+omAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117300dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample, sample_label = mnist.train.next_batch(1)\n",
    "print_mnist(0,sample, sample_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create a Convolutional Neural Network Model.\n",
    "You need to first create the model architecture by defining the input layer, the convolutional layer(s), the fully connected layer, the dropout layer, and the final output layer along with any necessary transformation to pass the data between each of them.\n",
    "\n",
    "\n",
    "\n",
    "<img src='../Images/cnn.png' style=\"width:800px;\"></img>\n",
    "\n",
    "Remember that the described steps for building a CNN are a complement to the image above. After each one you will find the sample code you will need for the model. You must declare some parameters, so you will need to understand the code provided to you. To build a CNN, follow these steps:\n",
    "\n",
    "\n",
    "__1. Define data (x) and dropout probability (keep). These are created with [placeholders](https://www.tensorflow.org/api_docs/python/tf/placeholder). See below for a code example.__\n",
    "```python\n",
    "x = tf.placeholder(tf.float32, [None, 28 * 28]) # 28 x 28 inputs\n",
    "keep = tf.placeholder(tf.float32)\n",
    "```\n",
    "\n",
    "__2. Reshape the input to be a 2D matrix. The [reshape](https://www.tensorflow.org/api_docs/python/tf/reshape) module in TensorFlow creates this dimension.__\n",
    "\n",
    "**Note:** Specify the image width, height, and depth correctly.d:\n",
    "```python\n",
    "x_image = tf.reshape(x, [-1, IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_DEPTH])\n",
    "```\n",
    "\n",
    "__3. Add two convolutional layers. See below for a code example:__\n",
    "    1. Use the [convolution](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d) of the previous layer’s output with this layer’s weight as the activation signal. \n",
    "    2. Have [relu](https://www.tensorflow.org/api_docs/python/tf/nn/relu) as the activation function with the sum of the bias and activation signals as features.  \n",
    "    3. Perform [max pooling](https://www.tensorflow.org/api_docs/python/tf/nn/max_pool) on the activation function:\n",
    "```python\n",
    "W_conv1 = tf.Variable(tf.truncated_normal([KERNEL_WIDTH, KERNEL_HEIGHT, IN_DEPTH, OUT_DEPTH], stddev=0.1))\n",
    "b_conv1 = tf.Variable(tf.constant(0.1, shape=[OUT_DEPTH]))\n",
    "a_conv1 = tf.nn.conv2d(x_image, W_conv1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "h_conv1 = tf.nn.relu(a_conv1 + b_conv1)\n",
    "h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, POOL_WIDTH, POOL_HEIGHT, 1],\n",
    "                        strides=[1, POOL_WIDTH, POOL_HEIGHT, 1], padding='SAME')\n",
    "```\n",
    "**Note:** The code shows that you will must create the weight and bias vectors for the\tlayer with [variable](https://www.tensorflow.org/api_docs/python/tf/Variable).\n",
    "\n",
    "__4. Reshape the convolutional layers output into a 1D vector. This creates the [reshaped](https://www.tensorflow.org/api_docs/python/tf/reshape) vector that will be used as input in the fully connected layer:__\n",
    "```python\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, CNN_NEURONS])\n",
    "```\n",
    "\n",
    "__5. Add a fully connected layer that will be structured with the weights and bias as [variable](https://www.tensorflow.org/api_docs/python/tf/Variable), and [relu](https://www.tensorflow.org/api_docs/python/tf/nn/relu) as the activation function with the sum of the [matrix multiplication](https://www.tensorflow.org/api_docs/python/tf/matmul) of the previous step’s output and this layer’s weight plus the bias as the features:__\n",
    "```python\n",
    "W_fc1 = tf.Variable(tf.truncated_normal([CNN_NEURONS, FULL_CONNECTED_NEURONS], stddev=0.1))\n",
    "b_fc1 = tf.Variable(tf.constant(0.1, shape=[FULL_CONNECTED_NEURONS]))\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "```\n",
    "\n",
    "__6. Add a dropout layer by using [dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) with the fully connected layer’s output, and the keep probability defined at the beginning as parameters:__\n",
    "```python\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep)\n",
    "```\n",
    "\n",
    "__7. Add a final output layer to classify the 10 possible different numbers with only the weight and bias as [variable](https://www.tensorflow.org/api_docs/python/tf/Variable) and the model’s output as the sum of [matrix multiplication](https://www.tensorflow.org/api_docs/python/tf/matmul)  of the previous layer’s output and this layer’s weight plus this layer’s bias:__\n",
    "```python\n",
    "W_fc2 = tf.Variable(tf.truncated_normal([FULL_CONNECTED_NEURONS, OUT_NEURONS], stddev=0.1))\n",
    "b_fc2 = tf.Variable(tf.constant(0.1, shape=[OUT_NEURONS]))\n",
    "model = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 28\n",
    "IMAGE_HEIGHT = 28\n",
    "IMAGE_DEPTH = 1\n",
    "\n",
    "KERNEL_WIDTH = 5\n",
    "KERNEL_HEIGHT = 5\n",
    "IN_DEPTH = 1\n",
    "OUT_DEPTH = 32\n",
    "\n",
    "IN_DEPTH2 = 32\n",
    "OUT_DEPTH2 = 64\n",
    "\n",
    "POOL_WIDTH = 2 \n",
    "POOL_HEIGHT = 2\n",
    "\n",
    "CNN_NEURONS = 7 * 7 * 64\n",
    "FULL_CONNECTED_NEURONS = 1024\n",
    "\n",
    "OUT_NEURONS = 10\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 28 * 28]) # 28 x 28 inputs\n",
    "keep = tf.placeholder(tf.float32)\n",
    "\n",
    "x_image = tf.reshape(x, [-1, IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_DEPTH])\n",
    "\n",
    "W_conv1 = tf.Variable(tf.truncated_normal([KERNEL_WIDTH, KERNEL_HEIGHT, IN_DEPTH, OUT_DEPTH], stddev=0.1))\n",
    "b_conv1 = tf.Variable(tf.constant(0.1, shape=[OUT_DEPTH]))\n",
    "a_conv1 = tf.nn.conv2d(x_image, W_conv1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "h_conv1 = tf.nn.relu(a_conv1 + b_conv1)\n",
    "h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, POOL_WIDTH, POOL_HEIGHT, 1],\n",
    "                        strides=[1, POOL_WIDTH, POOL_HEIGHT, 1], padding='SAME')\n",
    "\n",
    "W_conv2 = tf.Variable(tf.truncated_normal([KERNEL_WIDTH, KERNEL_HEIGHT, IN_DEPTH2, OUT_DEPTH2], stddev=0.1))\n",
    "b_conv2 = tf.Variable(tf.constant(0.1, shape=[OUT_DEPTH2]))\n",
    "a_conv2 = tf.nn.conv2d(h_pool1, W_conv2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "h_conv2 = tf.nn.relu(a_conv2 + b_conv2)\n",
    "h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1, POOL_WIDTH, POOL_HEIGHT, 1],\n",
    "                        strides=[1, POOL_WIDTH, POOL_HEIGHT, 1], padding='SAME')\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, CNN_NEURONS])\n",
    "\n",
    "W_fc1 = tf.Variable(tf.truncated_normal([CNN_NEURONS, FULL_CONNECTED_NEURONS], stddev=0.1))\n",
    "b_fc1 = tf.Variable(tf.constant(0.1, shape=[FULL_CONNECTED_NEURONS]))\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep)\n",
    "\n",
    "W_fc2 = tf.Variable(tf.truncated_normal([FULL_CONNECTED_NEURONS, OUT_NEURONS], stddev=0.1))\n",
    "b_fc2 = tf.Variable(tf.constant(0.1, shape=[OUT_NEURONS]))\n",
    "YOUR_MODEL = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Code Cell \n",
    "Execute the following code cell to look at your model’s output. You should see a list of 10 elements with random numbers to be on track as your output. If you see another output, you have an error in your CNN structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -5.20808983  -0.85434234 -16.16510582   3.06194234 -10.76761436\n",
      "    5.02383137   2.78716063   0.93128824  -0.34988204 -16.89151382]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    out = sess.run(YOUR_MODEL,\n",
    "                   feed_dict = {x: sample,\n",
    "                                keep: 1})\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Accuracy\n",
    "To measure the accuracy during training, you will compare the model’s classification with the correct labels. Use the average of the classification error count as the measure for the whole model. To accomplish this refer to sample code on each step:\n",
    "\n",
    "\n",
    "__1. Create a [placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for the correct label. Refer to the sample code below:__\n",
    "```python\n",
    "label = tf.placeholder(tf.float32, [None, 10])   # 10 outputs\n",
    "```\n",
    "**Note:** There are only 10 outputs.\n",
    "\n",
    "\n",
    "__2. Compare the model result with the correct label and average the results to get the accuracy. Do this by running the following commands:__\n",
    "```python\n",
    "correct_prediction = tf.equal(tf.argmax(model, 1), tf.argmax(label, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "```\n",
    "\n",
    "__3. Evaluate the accuracy over test samples from a TensorFlow session by using the function `print_accuracy` below:__\n",
    "```python\n",
    "def print_accuracy(sess):\n",
    "    accuracy_sum = 0\n",
    "    for i in range(100):\n",
    "        x_, y_ = mnist.test.next_batch(100)\n",
    "        accuracy_sum += sess.run(accuracy,\n",
    "                                 feed_dict={x: x_,\n",
    "                                 label: y_,\n",
    "                                 keep: 1})\n",
    "    print(accuracy_sum/100)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = tf.placeholder(tf.float32, [None, 10])   # 10 outputs\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(YOUR_MODEL, 1), tf.argmax(label, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "def print_accuracy(sess):\n",
    "    accuracy_sum = 0\n",
    "    for i in range(100):\n",
    "        x_, y_ = mnist.test.next_batch(100)\n",
    "        accuracy_sum += sess.run(accuracy,\n",
    "                                 feed_dict={x: x_,\n",
    "                                 label: y_,\n",
    "                                 keep: 1})\n",
    "    print(accuracy_sum/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Code Cell:\n",
    "Execute the following code cell to review your model’s accuracy. There should be one floating point value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.102800000105\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print_accuracy(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Test \n",
    "The next task is to create the training graph for your model and train it. To accomplish this task, follow the steps and refer to their code samples.\n",
    "\n",
    "__1. Create a placeholder for the alpha value in the momentum method as shown below.__\n",
    "```python\n",
    "alpha = tf.placeholder(tf.float32)\n",
    "```\n",
    "\n",
    "__2. Create the training graph by adding the required steps to minimize cross-entropy using the [MomentumOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/MomentumOptimizer).  To do this, refer to the following code sample:__\n",
    "```python\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=label, logits=model))\n",
    "train_graph = tf.train.MomentumOptimizer(learning_rate=LEARNING_RATE, momentum=alpha).minimize(cross_entropy)\n",
    "```\n",
    "\n",
    "__3. Train the model and print the accuracy of each epoch in a session by cycling through _epochS_ and _batches_ running the `train_graph` with data batches. Refer to the following code sample:__\n",
    "```python\n",
    "sess = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(20):\n",
    "    for batch in range(550):\n",
    "        x_, y_ = mnist.train.next_batch(100)\n",
    "            \n",
    "        alpha_ = 0.5\n",
    "        if epoch > 15:\n",
    "            alpha_ = 0.9\n",
    "        if epoch > 18:\n",
    "            alpha_ = 0.99\n",
    "            \n",
    "        sess.run(train_graph,\n",
    "                     feed_dict={x: x_,\n",
    "                                label: y_,\n",
    "                                alpha: alpha_,\n",
    "                                keep: 0.5})\n",
    "    print_accuracy(sess)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.01\n",
    "\n",
    "alpha = tf.placeholder(tf.float32)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=label, logits=YOUR_MODEL))\n",
    "train_graph = tf.train.MomentumOptimizer(learning_rate=LEARNING_RATE, momentum=alpha).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(20):\n",
    "    for batch in range(550):\n",
    "        x_, y_ = mnist.test.next_batch(100)\n",
    "            \n",
    "        alpha_ = 0.5\n",
    "        if epoch > 15:\n",
    "            alpha_ = 0.9\n",
    "        if epoch > 18:\n",
    "            alpha_ = 0.99\n",
    "            \n",
    "        sess.run(train_graph,\n",
    "                     feed_dict={x: x_,\n",
    "                                label: y_,\n",
    "                                alpha: alpha_,\n",
    "                                keep: 0.5})\n",
    "    print_accuracy(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Code Cell\n",
    "Execute the next code cell to print sample classification errors the final model made. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "to_print = 20\n",
    "cols = 4\n",
    "rows = to_print//cols\n",
    "fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(cols*3,rows*3))\n",
    "\n",
    "prints = 0\n",
    "done = False\n",
    "for batch in range(100):\n",
    "    x_, y_ = mnist.test.next_batch(100)\n",
    "    predictions = sess.run(YOUR_MODEL, feed_dict={x: x_,\n",
    "                                                      label: y_,\n",
    "                                                      keep: 1})\n",
    "    correct = sess.run(correct_prediction, feed_dict={x: x_,\n",
    "                                                         label: y_,\n",
    "                                                         keep: 1})\n",
    "    for i, is_correct in enumerate(correct):\n",
    "        if not is_correct:\n",
    "            print_mnist(i, x_, y_, predictions[i], \n",
    "                        axes[prints//cols, prints%cols])\n",
    "            prints += 1\n",
    "        if prints >= to_print:\n",
    "            done = True\n",
    "            break\n",
    "    if done:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "You created a functional Convolutional Neural Network to identify numbers from 0 to 9 that can be used in postal services or any other field. The number of inner layers, including their size, will have an impact on the model’s performance. Looking at the accuracy from each epoch you saw the effect of the gradient descent and possible drawbacks. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
