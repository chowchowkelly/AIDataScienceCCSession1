{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The MNIST data\n",
    "\n",
    "\n",
    "The MNIST data is comprised of pictures tha trepresent an number, and it includes the number label asociated to each picture. The data set is split into three parts: training (`mnist.train`), testing (`mnist.test`) and validation (`mnist.validation`) data. \n",
    "\n",
    "This split is very important: it's essential in machine learning that we have separate data which we don't learn from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model\n",
    "\n",
    "Common numerical computing libraries in Python use external code that are implemented in other languages. The latter to take advantage of languages that are more efficient. However, switching back to Python every operation causes an overhead. This overhead is especially bad if you want to run computations on GPUs or in a distributed manner (there is a high cost to transfere data).\n",
    "\n",
    "\n",
    "TensorFlow also does its heavy lifting outside Python. However, it does not run a single expensive operation independently from Python, TensorFlow lets us describe a graph of interacting operations that run entirely outside Python.\n",
    "\n",
    "#### What to do here?\n",
    "For this step. You need to create a TensorFlow graph that represents a Neural Network with no hidden layers, and an output layer comprised of 10 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "y = tf.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define cost funtion and optimizer\n",
    "\n",
    "In order to train the model, we need to define what it means to improve the results after each iteration. For that, we use a cost function an we try to minimize with respect to it. The cost function represents how far we are from our desired outcome. Minizing the error leads us to a better the model.\n",
    "\n",
    "A common cost function is called \"cross-entropy\". Cross-entropy takes advantage of large errors and reduces the learning slow-down that is caused because of traditional cost functions (i.e. quadratic cost function). In summary, it will take less to train a good model.\n",
    "\n",
    "#### What to do here?\n",
    "Create a tensor to represent the cross-entropy function. After that, create a tensor to represent a `GradientDescentOptimizer` that minimizes the cross-entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "  tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Tensorflow session\n",
    "\n",
    "We already have defined all our model (thus, we created a complete tensorflow graph). Now, we need to launch it. We create an interactive session and initialize all the variables defined before.\n",
    "\n",
    "#### What to do here?\n",
    "Create an `InteractiveSession` and run the global variables initializer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "MNIST is a large dataset. To train using a batch learning method would take a lot of time in between epochs. Therefore, we will use small batches of random data. This method is called stochastic training.\n",
    "\n",
    "#### What to do here?\n",
    "In a for loop, take 100 of random samples from mnist and run the train step using the resulting batches. Repeat the process as many times as needed to, in the end, present all the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate our model\n",
    "\n",
    "In order to figure out our model's precision, we need to compare our results with the expected output. To calculate the precision, you need to sum the correct classifications over the size of the testing dataset.\n",
    "\n",
    "#### What to do here?\n",
    "Create a Tensor that compares the model's output with the expected output. Then, determine the fraction that are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9207\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images,\n",
    "                                    y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "During the excercise we learned how to create a neural network and train it. We tested the performance of our model, and we found that the network arquitecture definition is important to obtain better results.\n",
    "\n",
    "We learned the importance of the initialilzation step (random numbers instead of zeroes), and how it impacts performance. Finally, it was showed that activation functions impact in performance too."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
